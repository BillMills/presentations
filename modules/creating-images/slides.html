<section data-background="images/title-whale.png" class="blue_bg">
	<h2>Creating Images</h2>
	<aside class="notes">
		In our discussion of running containers, we took the existance of these things called 'images' for granted, using them as the templates to define a container. In this module, we'll explore images in-depth, including a focus on creating and modifying images.
	</aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Images are Layered Filesystems</h2>
    <ul style='float:left; max-width: 47%;'>
    	<li>Images are composed of a stack of read-only layers.</li>
    	<li>Each stack begins with a <i>base image</i>.</li>
    	<li><i>Copy on write</i> strategy shares layers between images and containers to optimise performance.</li>
    </ul>
    <img src='images/lfs-1.png' style='float:right; max-width:50%'></img>

    <aside class="notes">
    	 - Images are composed in layers; each layer consists of a bunch of files that capture how this layer adapts the one beneath it.<br>
    	 - These stacks of layers always start with a base image, which typically captures only the base operating system for this image.<br>
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
	<h2>Sharing Layers</h2>
	<img src='images/lfs-2.png'></img>
	<ul>
		<li>Images can share layers in order to speed up transfer times and optimize disk and memory usage.</li>
		<li>Parent images that already exists on the host do not have to be downloaded.</li>
	</ul>

	<aside class="notes">
    	 - Layering has two main benefits: it allows any image to serve as the starting point for a new image (by adding more layers on top), and it offers a performance benefit by allowing us to share identical layers on disk and in memory between images and running containers.
	</aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>The Writable Container Layer</h2>
    <ul style='float:left; max-width: 47%;'>
    	<li>`docker run` creates a top writable layer for containers.</li>
    	<li>Parent images are read only.</li>
    	<li>All changes are made at the writeable layer.</li>
    	<li>When changing a file from a read only layer, the copy on write system will copy the file into the writable layer.</li>
    </ul>
    <img src='images/lfs-3.png' style='float:right; max-width:50%'></img>

    <aside class="notes">
    	 - Starting a container essentially adds a single writable layer to the image stack; since Docker is just adding this one thin layer, container startup is very fast and resource efficient.<br>
    	 - Any manipulations of the filesystem a container does is written only to this R/W layer; all image layers are always read-only.<br>
    	 - When a container edits a file from the base image, then and only then is that file copied to the R/W layer; this is what is meant by Docker's 'copy on write' filesystem; this also implies that the copy of a file that is visible in a running container is whichever copy of that file sits highest in the stack of filesystem layers.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Creating Images</h2>
    <p>There are three methods by which an image can be created:</p>
    <ul>
    	<li>Commit the R/W container layer as a new RO image layer.</li>
    	<li>Define new layers to add to a starting image in a <i>Dockerfile</i>.</li>
    	<li>Import a tarball into Docker as a standalone base layer</li>
    </ul>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Committing Container Changes</h2>
    <ul>
    	<li>Allows us to build images interactively, via terminal access to a running container.</li>
    	<li>Once satisfied with the state of a running container, the `docker commit` command saves the R/W layer as a new RO image layer, thus creating a new image.</li>
    </ul>
</section>

<section data-background="#00a2a1" class="green_bg">
	<h2><img src="images/icon_task.png" class="slide_icon" alt="icon"> Task: Interactive Image Creation</h2>
    <a href="https://www.katacoda.com/docker-training/courses/creating-images/interactive-image-creation">https://www.katacoda.com/docker-training/courses/creating-images/interactive-image-creation</a>
    <p>Scenario: Interactive Image Creation</p>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Image Namespaces</h2>
    <p>Images exist in one of three namespaces:</p>
    <ul>
    	<li><b>root</b>, like <pre>ubuntu:14.04</pre> or <pre>nginx</pre>, for official images.</li>
    	<li><b>user / org</b>, like <pre>username/myapp:1.0</pre>, for sharing images on Docker Hub.</li>
    	<li><b>self hosted</b>, like <pre>registry.mycompany.org:5000/myapp</pre>, for images hosted on a private registry.</li>
    </ul>

    <aside class="notes">
    	- In the exercise we made our new image under our user namespaces, but there are actually three namespaces that images can live in.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Dockerfiles</h2>
    <p>A Dockerfile is a configuration file that contains instructions for building a Docker image.</p>
    <ul>
    	<li>Essentially a contents manifest; doubles as documentation for image layers.</li>
    	<li>Allows integration of image creation into automated systems like CI/CD</li>
    </ul>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Dockerfiles</h2>
    <ul>
    	<li>All Dockerfiles begin with a `FROM` command that defines the image to base this new image off of.</li>
    	<li>Each subsequent command adds a layer to the image's file system</li>
    	<li>Once complete, the Dockerfile is used to build the image via `docker build`.</li>
    </ul>

    <pre>
    	# Comments begin with the pound sign
    	FROM ubuntu:14.04
    	RUN apt-get update
    	ADD /data /myapp/data
    	...
    </pre>
</section>

<section data-background="#00a2a1" class="green_bg">
	<h2><img src="images/icon_task.png" class="slide_icon" alt="icon"> Task: Creating Images with Dockerfiles</h2>
    <a href="https://www.katacoda.com/docker-training/courses/creating-images/creating-images-with-dockerfiles">https://www.katacoda.com/docker-training/courses/creating-images/creating-images-with-dockerfiles</a>
    <p>Scenario: Creating Images with Dockerfiles (steps 1-3)</p>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Build Output</h2>
    <img src='images/build-output.png'></img>

    <aside class="notes">
    	 - So far in the exercise, we've built some basic images from a Dockerfile. After running `docker build`, we should see some output that looks like this, with steps corresponding to each of the commands in the Dockerfile, either building that layer or fetching it from the cache.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Build Context</h2>
    <img src='images/build-context.png'></img>
    <ul>
    	<li>The build context is the directory that the Docker client sends to the Docker daemon during the docker build command.</li>
    	<li>Directory is sent as an archive.</li>
    	<li>Docker daemon will build using the files available in the context.</li>
    	<li>Specifying “.” for the build context means to use the current directory.</li>
    </ul>

    <aside class="notes">
    	 - The build process regularly mentions something called the build context - this is essentially the batch of files available to the docker daemon to build the image with. Everything needed from the local machine for building the image must be included in the build context.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Examining the Build Process</h2>
    <ul>
    	<li>
    		Each command after the `FROM` command launches a new container based on the image thusfar, and executes in that container:
    		<img src='images/process-1.png'></img>
    	</li>
    	<li>
    		At the end of each command, the resulting container's read-write layer is committed as a new image layer, and the container is deleted:
    		<img src='images/process-2.png'></img>
    	</li>
    	<li>
    		This is repeated for all commands in the Dockerfile; when the final command is complete, the resulting image is returned with the name and tag specified in the docker build command:
    		<img src='images/process-3.png'></img>
    	</li>
    </ul>

    <p>Note that the only thing persisted between commands are things written to the filesystem - NOT state like filesystem position or running processes!</p>

    <aside class="notes">
    	 - Building with dockerfiles does the same thing as an interactive build under the hood; each command other than `FROM` starts a container on the image thusfar, executes, and then commits the resulting container's r/w layer as the newest image layer on the top of the image stack.<br>
    	 - A common rookie mistake is to forget the final point: stateful things are NOT persisted from command to command! So doing something like cd'ing into a directory in one command and then executing a script in another will fail or produce unexpected results.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Examining the Build Process</h2>

    <p>This:</p>
    <pre>
    	RUN cd /src
    	RUN bash setup.sh
    </pre>

    <p>is different than this:</p>
    <pre>
    	RUN cd /src && bash setup.sh
    </pre>

    <p>because every Dockerfile command runs in a different container, and only the filesystem, not the in-memory state, is persisted from layer to layer.</p>

</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Build Cache</h2>
    <ul>
    	<li>Docker saves a snapshot of the image after each build step.</li>
    	<li>Before executing a step, Docker checks to see if it has already run that build sequence previously.</li>
    	<li>If yes, Docker will use the result of that instead of executing the instruction again.</li>
    	<li>Docker uses exact strings in your Dockerfile to compare with the cache; <b>simply changing the order of instructions will invalidate the cache.</b></li>
    	<li>To disable the cache manually use the <pre>--no-cache</pre> flag when running <pre>docker build</pre>.</li>
    </ul>

</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Default Commands via `CMD` and `ENTRYPOINT`</h2>
    <ul>
    	<li>Recall all containers run a process as their PID 1: <pre>docker run <image> <command></pre></li>
    	<li><pre>CMD</pre> and <pre>ENTRYPOINT</pre> allow us to specify defaults in the Dockerfile</li>
    	<li>Main difference between the two is that <pre>CMD</pre> is overridden by a command supplied in <pre>docker run</pre>, but <pre>ENTRYPOINT</pre> is not.</li>
    </ul>

    <aside class='notes'>
    	- Another pair of helpful commands in Dockerfiles are CMD and ENTRYPOINT<br>
    	- These are used for specifying default processes and options to run in containers created from this image.<br>
    	- The differences between the two are a bit subtle; let's explore them in the next few steps of the exercise.
    </aside>
</section>

<section data-background="#00a2a1" class="green_bg">
	<h2><img src="images/icon_task.png" class="slide_icon" alt="icon"> Task: Creating Images with Dockerfiles</h2>
    <a href="https://www.katacoda.com/docker-training/courses/creating-images/creating-images-with-dockerfiles">https://www.katacoda.com/docker-training/courses/creating-images/creating-images-with-dockerfiles</a>
    <p>Scenario: Creating Images with Dockerfiles (steps 4-6)</p>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Default Commands via `CMD` and `ENTRYPOINT`</h2>
    <ul>
    	<li><pre>CMD</pre> alone provides a default command and list of parameters for that command to run in a container created from this image.</li>
    	<li><pre>CMD</pre> combined with <pre>ENTRYPOINT</pre> provides default parameters for the command specified by <pre>ENTRYPOINT</pre>.</li>
    	<li><pre>CMD</pre> is always overridden by command arguments to <pre>docker run</pre>, but <pre>ENTRYPOINT</pre> is not.</li>
    	<li>The <pre>ENTRYPOINT</pre> command itself can be overridden with the <pre>--entrypoint</pre> flag to <pre>docker run</pre>.</li>
    </ul>

    <aside class='notes'>
    	 - In practice, CMD is for providing overridable defaults, while ENTRYPOINT is for making a container act more like an executable.<br>
    	 - Oftentimes images are designed to do exactly one thing; CMD and ENTRYPOINT allow you to bake that intention right into the image, by pre-specifying that command.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Shell vs. exec format</h2>
   	<p>Superficially, the following two syntaxes for <pre>CMD</pre> and <pre>ENTRYPOINT</pre> commands are the same:</p>
   	<ul>
   		<li><pre>apt-get update</pre> (shell form)</li>
   		<li><pre>["apt-get", "update"]</pre> (exec form)</li>
   	</ul>
   	<p>But there are some subtle differences:</p>
   	<ul>
   		<li>Shell form allows for the parsing of variables like <pre>CMD sudo -u ${USER} java ...</pre></li>
   		<li>Exec form can run in a container with no shell; shell form always runs via <pre>/bin/sh -c</pre></li>
   		<li>Shell form for <pre>ENTRYPOINT</pre> prevents options from being overridden by <pre>CMD</pre> or <pre>docker run</pre>.</li>
   		<li>Note that exec form is formal JSON - double quotes mandatory.</li>
   	</ul>

    <aside class='notes'>
    	 - CMD, ENTRYPOINT and RUN commands can use either exec or shell syntax<br>
    	 - exec is generally preferred for ENTRYPOINT, since it preserves the ability to override options.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>"It works on my laptop, I swear!"</h2>

    <p>To build a simple Java application, we typically need:</p>
    <ul>
    	<li>The Java Development Kit (JDK)</li>
    	<li>The Java Virtual Machine (JVM)</li>
    	<li>A bunch of case-specific libraries and other deps</li>
    </ul>
    <p>A perfectly healthy Java app will therefore break when migrated to a new environment if:</p>
    <ul>
    	<li>Missing JDK / JVM</li>
    	<li>Wrong versions of JDK or JVM</li>
    	<li>Missing libraries</li>
    	<li>Wrong versions of libraries</li>
    </ul>
    <p>Capturing all dependencies and environment setup steps in a Dockerfile is the easiest way to make your application reliably portable.</p>

    <aside class='notes'>
    	- Now that we've written a basic Dockerfile, we have (most of) what we need to begin containerizating applications.<br>
    	- A big part of the promise of Docker is to let us run any app, anywhere, by making our running environments encapsulated and portable<br>
    	- Writing a Dockerfile allows us to set up a containerized environment by following the same steps we would setting up on bare metal, making it as easy as possible to take what you know about deploying your app, and translating that essentially literally into a containerized environment.
    </aside>
</section>

<section data-background="#00a2a1" class="green_bg">
	<h2><img src="images/icon_task.png" class="slide_icon" alt="icon"> Task: Dockerizing an Application</h2>
    <a href="https://www.katacoda.com/docker-training/courses/creating-images/dockerizing-an-application">https://www.katacoda.com/docker-training/courses/creating-images/dockerizing-an-application</a>
    <p>Scenario: Dockerizing an Application</p>

    <aside class='notes'>
    	Please ensure all student lab machines are using Linux kernel version 4.2.0-30-generic. Certain older kernel versions such as 4.2.0-23-generic contain a flaw whereby Java processes running in a Docker container will freeze and refuse to terminate. Not even a sudo kill -9 [pid] will shut down the process. The Docker container will refuse to shutdown and you won’t be able to restart the engine. Eventually the process becomes a zombie process and chews up all the VM resources, effectively destroying the machine.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>`COPY` and `ADD` commands</h2>

    <p><pre>COPY</pre> copies files from a source in your build context to a destination in your image:</p>
    <pre>COPY <src> <dest></pre>

    <p>The <pre>ADD</pre> command is nearly identical, with identical syntax; <pre>ADD</pre> can however automatically unpack tar files and fetch things from URLs.</p>

    <p>In both cases, a checksum for the files added is calculated and logged in the build cache; the cache will be invalidated if the checksum mismatches, so that files will be re-added if they've changed since the last <pre>docker build</pre>.</p>

    <aside class='notes'>
    	 - We saw the COPY command in the last exercise; there is also the nearly identical ADD command. In either case, the build process is smart enough to use a checksum against the files to be added to bust the cache in the case that those files have changed; otherwise, updates to those files wouldn't get picked up by the build process as nothing in the Dockerfile itself appears different.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>`MAINTAINER` and `ENV` commands</h2>

    <ul>
    	<li>
    		<pre>MAINTAINER</pre> allows us to bake a maintainer identity right into the image:
    		<pre>MAINTAINER Docker Training <education@docker.com></pre>
    	</li>
    	<li>
    		<pre>ENV</pre> allows environment variables to be set inside our images:
    		<pre>ENV APP_PORT 8080</pre>
    	</li>
    	<li>Many more Dockerfile commands are available; see the docs at <a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a></li>
    </ul>

    <aside class='notes'>
    	- We've only touched on the greatest hits of Dockerfile commands; see the docs for more.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Dockerfile best practises: layers</h2>

    <ul>
    	<li>Start from an official image, like <pre>ubuntu</pre>, <pre>postgres</pre> or <pre>nginx</pre>. These are vetted for security by Docker and vendor partners.</li>
    	<li>Avoid making an unneccesarily large number of layers by combining similar commands, either via native utility functionality (<pre>RUN pip install x y z</pre> rather than installing x, y and z with separate <pre>RUN</pre> commands), or by chaining commands together with <pre>&&</pre>. Don't add deps you don't really need.</li>
    	<li>One <pre>ENTRYPOINT</pre> per Dockerfile.</li>
    </ul>

    <aside class='notes'>
    	- Now that we have the mechanics of making Dockerfiles, there's also a number of optional best practises to consider.<br>
    	- Base your images off of official images whenever possible; you can recognize these on Dockerhub as they don't have an explicit namespace like vendor/product; they're just single-word names, possibly with a tag. These are all battle-tested images produced in collaboration between the product vendors and Docker, and are scanned regularly for security vulnerabilities.<br>
    	- Deciding exactly what to combine into how many layers is a bit of an art; too many layers can make building and running cumbersome, but too few results in illegible Dockerfiles.<br>
    	- Not only does only the last ENTRYPOINT in a Dockerfile actually have an effect, but more fundamentally, a container only ever runs a single process; good image design demands making minimal images with just enough installed to run the one process this container is desgined to run.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Dockerfile best practises: caching</h2>
    <p>Use the caching system to your advantage for faster build times:</p>
    <ul>
    	<li>The order of commands matters, since as soon as one layer has to be rebuilt, the cache is abandoned for all subsequrnt layers.</li>
    	<li>Therefore, put things that don't change often nearer the top of your Dockerfile.</li>
    	<li>Remember that <pre>COPY</pre> and <pre>ADD</pre> perform checksums against everything they include in the image; if anything changes, the whole cache is invalidated from that point on.</li>
    </ul>

    <img src='images/bad-cache.png'></img>

    <aside class='notes'>
    	- One of the most common things for new users to struggle with is using the build cache well.<br>
    	- Make sure to put oft-changing things near the bottom of the Dockerfile, so changing them doesn't invalidate the cache for your foundational dependencies. Most Dockerfiles start with a bunch of dependency installation that rarely changes.<br>
    	- Common gotcha is to forget that <pre>RUN</pre> doesn't perform any checksums against resources it references. In the figure, if anything in the webapp directory has changed, the cache will be busted and the install procedure will be rerun, even if requirements.txt wasn't the thing that changed.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Dockerfile best practises: caching</h2>
    <p>Better caching behavior will come from the Dockerfile below:</p>
    <ul>
    	<li>Only <pre>requirements.txt</pre> is added by <pre>ADD</pre>, so the checksum is for that file alone.</li>
    	<li>Therefore, the cache won't be invalidated if <pre>requirements.txt</pre> hasn't changed, and the <pre>RUN</pre> command can be grabbed from the cache without reinstalling</li>
    	<li>The rest of the contents of <pre>./webapp</pre> can be picked up afterwards.</li>
    </ul>

    <img src='images/bad-cache.png'></img>

    <aside class='notes'>
    	- Here's a more deft use of the cache, that avoids reinstallation unless absolutely necessary.<br>
    	- The other side of the no-checksum-for-RUN-commands coin is that sometimes the cache is used even when things have changed; common example is RUN commands to pull a git repo. If the literal RUN command hasn't changed in the Dockerfile and no previous line has busted the cache, the RUN command will get pulled from the cache no matter how different your remote repo is since last time you built.
    </aside>
</section>

<section data-background="#1AAAF8" class="blue_bg">
    <h2>Module Summary</h2>

    <ul>
    	<li>Images are built out of read-only layers.</li>
    	<li>Creating a container adds a thin read-write layer on top of an image; images and containers share substrate layers wherever possible.</li>
    	<li>Images are built up by committing the R/W container layer, one at a time.</li>
    	<li>This can be done by hand, but is very cumbersome.</li>
    	<li>Preferred method for building images is via Dockerfiles.</li>
    	<li>Key Dockerfile commands: <pre>FROM</pre>, <pre>RUN</pre>, <pre>COPY</pre> and <pre>ENTRYPOINT</pre></li>
    	<li>Key API object for building images: <pre>docker build</pre></li>
    </ul>

</section>


